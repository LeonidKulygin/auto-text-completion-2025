{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14ed645a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\projects2025\\Yandex\\autotext\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "from transformers import AutoTokenizer\n",
    "from torch.optim import Adam\n",
    "import evaluate\n",
    "\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeaf7d84",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7c4a2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.next_token_dataset import AutoTextDataset, collate_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a20d76dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val, test = pd.read_csv('data/train.csv'), pd.read_csv('data/val.csv'), pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0fdfdded",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainds, valds, testds = AutoTextDataset(train), AutoTextDataset(val), AutoTextDataset(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f81f9b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_laoder, val_loader, test_loader = DataLoader(trainds, shuffle=True, batch_size=64 ,collate_fn=collate_fn),\\\n",
    "                                        DataLoader(valds, shuffle=False, batch_size=32 ,collate_fn=collate_fn),\\\n",
    "                                        DataLoader(testds, shuffle=False, batch_size=32 ,collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5afa3f42",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a9f31eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.gru_model import GRUmodel\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b8bbe9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GRUmodel(\n",
       "  (emb): Embedding(50257, 128, padding_idx=50256)\n",
       "  (gru): GRU(128, 64, batch_first=True)\n",
       "  (fc): Linear(in_features=64, out_features=50257, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1 = GRUmodel()\n",
    "model1.load_state_dict(torch.load('models/gru_model_autotest.pth', map_location='cuda'))\n",
    "model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d386f424",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9736849"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([p.numel() for p in model1.parameters()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f5db5ad",
   "metadata": {},
   "source": [
    "for training model move to ```gru_train_solution.ipynb```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9904c8f9",
   "metadata": {},
   "source": [
    "### Metrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "88836dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.eval_gru import val_loop\n",
    "device = 'cuda'\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=50256)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"openai-community/gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12e054c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4.736642544245048,\n",
       " {'rouge1': np.float64(0.11666666666666665),\n",
       "  'rouge2': np.float64(0.01818181818181818),\n",
       "  'rougeL': np.float64(0.09984126984126984),\n",
       "  'rougeLsum': np.float64(0.09984126984126984)},\n",
       " [(\" should send apple an angry email along the lines of &quot;hey d-bags, 'we fixed your computer' generally means you actually did something.&quot;.\",\n",
       "   \" you're too. &lt;3. i'm so excited. i barely have a good day\"),\n",
       "  ('ad munchkin today...why is fort william so far away? stupid fort william. also, stupid jimmy chungs only doing breakfast in jul/aug',\n",
       "   \"ustaaaaaah. but i'm so tired. no sleep in my house. thx fer\"),\n",
       "  (\" only just following me!! tut tut!! how's life?? we av neva met up since i've been bk to bpool and ur leaving soon!\",\n",
       "   ' &lt;3 miss you guys! hahahhaha! ;) night xoxo:'),\n",
       "  ('!? nooo, you need to get it she has twitter? haha cool. i love you too denisse.&lt;3',\n",
       "   ' fame. xxx â\\x99¥ love you! â\\xa0 itâ´s'),\n",
       "  ('orders, why do you put out a coupon that is only good monday-thursday? some of us work days and evenings...',\n",
       "   \"ulin'; you'll see a pic. hope your reality is better! thanks! xx x\")])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_loop(val_loader, model1.to('cuda'), criterion, tokenizer, device, num_samples=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "27d100db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4.736921673189635,\n",
       " {'rouge1': np.float64(0.056582234042284504),\n",
       "  'rouge2': np.float64(0.0),\n",
       "  'rougeL': np.float64(0.055754577117066606),\n",
       "  'rougeLsum': np.float64(0.0576369472921197)},\n",
       " [(\"iinq and waitinq to leave naenae's house ! i do not wanna stay here ; ! borinq as _____x :[ : i wish i was at home ! im nvr home tho\",\n",
       "   ' nyd sis tho. my bf got outta his apt. :/shii'),\n",
       "  (\" i'm going 2 go 2 the cinco de mayo fiesta at centennial olympic park today. cinco won't be the same w/ out the ls's though\",\n",
       "   ' :| lol. i like sundays. it was goodly too long fun. wait until again'),\n",
       "  (' comes the sun! come to nectar for happy hour w/ dj sosa of goods crew for throwback cuts, food &amp; drink specials! party on the patio',\n",
       "   ' nd it! wimma hunt! and ur not? xx xx xxx love you.'),\n",
       "  (\"'re such a pig dil... did u know i ate 3 slices of cake n a bunch of sushissss tday for lunch sad faceeee!!!\",\n",
       "   ' ur awesome song!! xxo!! i love u. aww i love ya.&lt;'),\n",
       "  (\" thought of going to uni but i just remembered that it's a bank holiday..!? i wanna seeee my supervisor so badlyyyyy\",\n",
       "   '! xd drel w/a jah? yay! #t1n97')])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_loop(test_loader, model1.to('cuda'), criterion, tokenizer, device, num_samples=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2736b61",
   "metadata": {},
   "source": [
    "### GPT2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d5d22e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\projects2025\\Yandex\\autotext\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from src.eval_transformer_pipeline import run_gpt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8a03d586",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "124439808"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM\n",
    "model = AutoModelForCausalLM.from_pretrained(\"openai-community/gpt2\")\n",
    "sum([p.numel() for p in model.parameters()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf521c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5252 [00:00<?, ?it/s]The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "100%|██████████| 5252/5252 [08:22<00:00, 10.46it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val — Loss: 5.3497, ROUGE-1: 0.1102, ROUGE-2: 0.0208,  ROUGE-L: 0.0747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5252/5252 [07:02<00:00, 12.42it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test — Loss: 5.3497, ROUGE-1: 0.1171, ROUGE-1: 0.0351, ROUGE-L: 0.1004\n"
     ]
    }
   ],
   "source": [
    "run_gpt2() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa896ac",
   "metadata": {},
   "source": [
    "### Результаты \n",
    "\n",
    "Относительная неглубовая GRU модель (9736849 параметров), обученная на 16 эпох, показала на val по всем ключевым метрикам лучше результат, чем предобученный gpt2 (124439808 параметров, что в 13 раз больше первой модели).\n",
    "По val: \n",
    "- Loss 4.7366 и 5.3497 \n",
    "- ROUGE-1: 0.1167 и 0.1102\n",
    "\n",
    "По test:\n",
    "- Loss 4.7369 и 5.3497 \n",
    "- ROUGE-1: 0.0566 и 0.1171\n",
    "- ROUGE-2: 0.0 и 0.0351\n",
    "- ROUGE-L: 0.05575 и 0.1004\n",
    "\n",
    "Однако, на тесте по метрике ROUGE-1 наблюдаем ухудшение метрик, что говорит о переобучении модели. =(. Лучше всего улучшать модель регуляризацией, взять AdamW, добавить dropout. Хотя по лосс в модели не наблюдается переобучение. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c589d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autotext (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
