# auto-text-completion-2025


# Выводы

Относительная неглубовая GRU модель (9736849 параметров), обученная на 16 эпох, показала на val по всем ключевым метрикам лучше результат, чем предобученный gpt2 (124439808 параметров, что в 13 раз больше первой модели).
По val: 
- Loss 4.7366 и 5.3497 
- ROUGE-1: 0.1167 и 0.1102

По test:
- Loss 4.7369 и 5.3497 
- ROUGE-1: 0.0566 и 0.1171
- ROUGE-2: 0.0 и 0.0351
- ROUGE-L: 0.05575 и 0.1004

Однако, на тесте по метрике ROUGE-1 наблюдаем ухудшение метрик, что говорит о переобучении модели. =(. Лучше всего улучшать модель регуляризацией, взять AdamW, добавить dropout. Хотя по лосс в модели не наблюдается переобучение. 

# Структура проекта 

```text
text-autocomplete/
├── data/                            # Датасеты
│   ├── raw_dataset.csv              # "сырой" скачанный датасет
│   └── dataset_processed.csv        # "очищенный" датасет
│   ├── train.csv                    # тренировочная выборка
│   ├── val.csv                      # валидационная выборка
│   └── test.csv                     # тестовая выборка
│
├── src/                             # Весь код проекта
│   ├── data_utils.py                # Обработка датасета
|   ├── next_token_dataset.py        # код с torch Dataset'ом 
│   ├── gru_model.py                 # код lstm модели
|   ├── eval_gru.py                  # замер метрик lstm модели
|   ├── gru_train.py                 # код обучения модели
|   ├── eval_transformer_pipeline.py # код с запуском и замером качества трансформера
│
├── configs/                         # yaml-конфиги с настройками проекта
│
├── models/                          # веса обученных моделей
|
├── gru_train_solution.ipynb         # ноутбук с обучением 
|
├── solution.ipynb                   # ноутбук с решением
|
├── eda.ipynb                        # черновик и тесты
|
└── requirements.txt                 # зависимости проекта
```

### Этап 0. Подготовка окружения
Подготовьте окружение. Используйте файл requirements_sprint_2_project.txt. +DONE
Создайте git-репозиторий. Подумайте над структурой проекта. Можете заранее создать некоторые файлы, в которых будете писать код.

### Этап 1. Сбор и подготовка данных
Скачайте датасет, положите его в папку data.
«Почистите» тексты в датасете, а затем токенизируйте их. Для удобства можете сохранить почищенный и токенизированный датасет.
Разбейте датасет на трейн, валидацию и тест.
Создайте torch.Dataset и torch.DataLoader для обучения модели.

### Этап 2. Реализация рекуррентной сети
Напишите код модели на основе LSTM. В методе forward модель должна принимать на вход последовательность токенов и предсказывать следующий токен.
Дополнительно для модели реализуйте метод генерации нескольких токенов.

### Этап 3. Тренировка модели
Напишите код замера и вывода метрики ROUGE. В коде модель должна проходиться по DataLoader'у и генерировать автодополнения, которые затем будут сравниваться с таргетом. 
Для простоты реализуйте сценарий, где в качестве входа модель получает 3/4 исходного текста и старается дополнить оставшиеся 1/4.
Напишите код тренировки модели, во время тренировки выводите значения функции потерь и метрики ROUGE.
Обучите модель, подобрав оптимальные параметры. Во время тренировки или после неё выведите некоторые примеры автодополнений, которые выучила модель. Ориентировочное время тренировки: несколько минут на одну эпоху при размере батча около 256 и размерности скрытого слоя LSTM около 128. Так как тексты ограничены по длине, а памяти на видеокарте хватает с запасом, то можно ставить размер батча и размерности модели и побольше.

### Этап 4. Использование предобученного трансформера
Воспользуйтесь моделью трансформера distilgpt2 из Transformers и дополните тексты из датасета.
Напишите код замера и вывода метрики ROUGE, но уже с использованием трансформера. Здесь, как и с LSTM, предсказывайте последнюю четверть текста.
Подберите параметры генерации, замерьте качество модели на валидационной выборке, выведите примеры предсказаний.

### Этап 5. Формулирование выводов
Сравните примеры предсказаний двух моделей, а также получившиеся метрики.
Сделайте выводы о том, какую модель лучше использовать и почему.



