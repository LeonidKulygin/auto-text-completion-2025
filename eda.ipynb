{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2226a157",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\projects2025\\Yandex\\autotext\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import AutoTokenizer\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import re\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from src.data_utils import preprocessing_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09016efe",
   "metadata": {},
   "source": [
    "### Raw dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d1eeaddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tweets.txt', encoding='utf-8') as f:\n",
    "    s = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d1ab3c82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"is upset that he can't update his Facebook by texting it... and might cry as a result  School today also. Blah!\\n\""
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "dde8ddfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>my whole body feels itchy and like its on fire \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1600493</th>\n",
       "      <td>Ask Programming: LaTeX or InDesign?: submitted...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1600494</th>\n",
       "      <td>On that note, I hate Word. I hate Pages. I hat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1600495</th>\n",
       "      <td>Ahhh... back in a *real* text editing environm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1600496</th>\n",
       "      <td>Trouble in Iran, I see. Hmm. Iran. Iran so far...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1600497</th>\n",
       "      <td>Reading the tweets coming out of Iran... The w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1600498 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      text\n",
       "0        @switchfoot http://twitpic.com/2y1zl - Awww, t...\n",
       "1        is upset that he can't update his Facebook by ...\n",
       "2        @Kenichan I dived many times for the ball. Man...\n",
       "3        my whole body feels itchy and like its on fire \\n\n",
       "4        @nationwideclass no, it's not behaving at all....\n",
       "...                                                    ...\n",
       "1600493  Ask Programming: LaTeX or InDesign?: submitted...\n",
       "1600494  On that note, I hate Word. I hate Pages. I hat...\n",
       "1600495  Ahhh... back in a *real* text editing environm...\n",
       "1600496  Trouble in Iran, I see. Hmm. Iran. Iran so far...\n",
       "1600497  Reading the tweets coming out of Iran... The w...\n",
       "\n",
       "[1600498 rows x 1 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data  = pd.DataFrame()\n",
    "data['text'] = s\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "dd0667b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('data/raw_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "749184bf",
   "metadata": {},
   "source": [
    "### Raw Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6a11cb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>my whole body feels itchy and like its on fire \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1600493</th>\n",
       "      <td>Ask Programming: LaTeX or InDesign?: submitted...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1600494</th>\n",
       "      <td>On that note, I hate Word. I hate Pages. I hat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1600495</th>\n",
       "      <td>Ahhh... back in a *real* text editing environm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1600496</th>\n",
       "      <td>Trouble in Iran, I see. Hmm. Iran. Iran so far...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1600497</th>\n",
       "      <td>Reading the tweets coming out of Iran... The w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1600498 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      text\n",
       "0        @switchfoot http://twitpic.com/2y1zl - Awww, t...\n",
       "1        is upset that he can't update his Facebook by ...\n",
       "2        @Kenichan I dived many times for the ball. Man...\n",
       "3        my whole body feels itchy and like its on fire \\n\n",
       "4        @nationwideclass no, it's not behaving at all....\n",
       "...                                                    ...\n",
       "1600493  Ask Programming: LaTeX or InDesign?: submitted...\n",
       "1600494  On that note, I hate Word. I hate Pages. I hat...\n",
       "1600495  Ahhh... back in a *real* text editing environm...\n",
       "1600496  Trouble in Iran, I see. Hmm. Iran. Iran so far...\n",
       "1600497  Reading the tweets coming out of Iran... The w...\n",
       "\n",
       "[1600498 rows x 1 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data/raw_dataset.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5561e0d8",
   "metadata": {},
   "source": [
    "### Классическая очистка\n",
    "\n",
    "1. Привести к нижнему регистру;\n",
    "2. удалить ссылки, упоминания, эмодзи (по необходимости); \n",
    "- ОФФТОП а вообще прикольно оставить спец символы и эмодзи как измерение галлюцинации... Такой шум в исходных данных + тогда надо чистить их через regex\n",
    "s = regex.sub(r'[^\\p{L}\\p{N}\\s]', ' ', s)\n",
    "\n",
    "3. убрать n-ые пробелы \n",
    "3. заменить нестандартные символы;\n",
    "4. токенизировать текст."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cdfe6a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data_utils import preprocessing_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "884c91d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[12, 257, 2503, 11, 326, 338, 257, 275, 31647,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[271, 9247, 326, 339, 460, 470, 4296, 465, 239...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[72, 288, 1572, 867, 1661, 329, 262, 2613, 13,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[1820, 2187, 1767, 5300, 340, 29658, 290, 588,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[3919, 11, 340, 338, 407, 37722, 379, 477, 13,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1600493</th>\n",
       "      <td>[2093, 8300, 25, 47038, 393, 773, 274, 570, 27...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1600494</th>\n",
       "      <td>[261, 326, 3465, 11, 1312, 5465, 1573, 13, 131...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1600495</th>\n",
       "      <td>[993, 12337, 986, 736, 287, 257, 1635, 5305, 9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1600496</th>\n",
       "      <td>[83, 472, 903, 287, 4173, 272, 11, 1312, 766, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1600497</th>\n",
       "      <td>[25782, 262, 12665, 2406, 503, 286, 4173, 272,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1600498 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    tokens\n",
       "0        [12, 257, 2503, 11, 326, 338, 257, 275, 31647,...\n",
       "1        [271, 9247, 326, 339, 460, 470, 4296, 465, 239...\n",
       "2        [72, 288, 1572, 867, 1661, 329, 262, 2613, 13,...\n",
       "3        [1820, 2187, 1767, 5300, 340, 29658, 290, 588,...\n",
       "4        [3919, 11, 340, 338, 407, 37722, 379, 477, 13,...\n",
       "...                                                    ...\n",
       "1600493  [2093, 8300, 25, 47038, 393, 773, 274, 570, 27...\n",
       "1600494  [261, 326, 3465, 11, 1312, 5465, 1573, 13, 131...\n",
       "1600495  [993, 12337, 986, 736, 287, 257, 1635, 5305, 9...\n",
       "1600496  [83, 472, 903, 287, 4173, 272, 11, 1312, 766, ...\n",
       "1600497  [25782, 262, 12665, 2406, 503, 286, 4173, 272,...\n",
       "\n",
       "[1600498 rows x 1 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "datatest = pd.DataFrame()\n",
    "datatest['tokens'] = preprocessing_data(data)\n",
    "datatest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ae107424",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5562,\n",
       " 338,\n",
       " 826,\n",
       " 288,\n",
       " 7737,\n",
       " 467,\n",
       " 2539,\n",
       " 815,\n",
       " 307,\n",
       " 503,\n",
       " 8326,\n",
       " 45630,\n",
       " 272,\n",
       " 21580,\n",
       " 220,\n",
       " 50256]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datatest.tokens.sample(1).iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe2de0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "datatest.to_csv('data/dataset_processed.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b9adfbf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[12, 257, 2503, 11, 326, 338, 257, 275, 31647,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[271, 9247, 326, 339, 460, 470, 4296, 465, 239...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[72, 288, 1572, 867, 1661, 329, 262, 2613, 13,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[1820, 2187, 1767, 5300, 340, 29658, 290, 588,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[3919, 11, 340, 338, 407, 37722, 379, 477, 13,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1600493</th>\n",
       "      <td>[2093, 8300, 25, 47038, 393, 773, 274, 570, 27...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1600494</th>\n",
       "      <td>[261, 326, 3465, 11, 1312, 5465, 1573, 13, 131...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1600495</th>\n",
       "      <td>[993, 12337, 986, 736, 287, 257, 1635, 5305, 9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1600496</th>\n",
       "      <td>[83, 472, 903, 287, 4173, 272, 11, 1312, 766, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1600497</th>\n",
       "      <td>[25782, 262, 12665, 2406, 503, 286, 4173, 272,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1600498 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    tokens\n",
       "0        [12, 257, 2503, 11, 326, 338, 257, 275, 31647,...\n",
       "1        [271, 9247, 326, 339, 460, 470, 4296, 465, 239...\n",
       "2        [72, 288, 1572, 867, 1661, 329, 262, 2613, 13,...\n",
       "3        [1820, 2187, 1767, 5300, 340, 29658, 290, 588,...\n",
       "4        [3919, 11, 340, 338, 407, 37722, 379, 477, 13,...\n",
       "...                                                    ...\n",
       "1600493  [2093, 8300, 25, 47038, 393, 773, 274, 570, 27...\n",
       "1600494  [261, 326, 3465, 11, 1312, 5465, 1573, 13, 131...\n",
       "1600495  [993, 12337, 986, 736, 287, 257, 1635, 5305, 9...\n",
       "1600496  [83, 472, 903, 287, 4173, 272, 11, 1312, 766, ...\n",
       "1600497  [25782, 262, 12665, 2406, 503, 286, 4173, 272,...\n",
       "\n",
       "[1600498 rows x 1 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv(\"data/dataset_processed.csv\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07981901",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "796bb5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "train, val = train_test_split(datatest, test_size=0.3, random_state=42)\n",
    "val, test = train_test_split(val, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7c17516b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('data/train.csv', index=False)\n",
    "val.to_csv('data/val.csv', index=False)\n",
    "test.to_csv('data/test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d119959",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train.csv')\n",
    "val = pd.read_csv('data/val.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a3dfe87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94240e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "\n",
    "\n",
    "class AutoTextDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.tokens = data.tokens\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.tokens)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        token = eval(self.tokens[index])\n",
    "        return {\n",
    "            'x': torch.tensor(token[:-1]),\n",
    "            'y': torch.tensor(token[1:])\n",
    "        }\n",
    "def collate_fn(batch):\n",
    "    l = torch.tensor([len(item['x']) for item in batch])\n",
    "    sort_ind = torch.argsort(l, descending=True)\n",
    "    x = [item['x'] for item in batch]\n",
    "    y = [item['y'] for item in batch]\n",
    "    \n",
    "    sort_x = [x[i] for i in sort_ind]\n",
    "    sort_y = [y[i] for i in sort_ind]\n",
    "\n",
    "    pad_x = pad_sequence(sort_x, batch_first=True, padding_value=50256)\n",
    "    pad_y = pad_sequence(sort_y, batch_first=True, padding_value=50256)\n",
    "    return {\n",
    "        'lengths': [l[i] for i in sort_ind], \n",
    "        'x': pad_x, \n",
    "        'y': pad_y, \n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4233d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "from transformers import AutoTokenizer\n",
    "from torch.optim import Adam\n",
    "import evaluate  \n",
    "\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "\n",
    "\n",
    "class AutoTextDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.tokens = data.tokens\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.tokens)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        token = eval(self.tokens[index])\n",
    "        return {\n",
    "            'x': torch.tensor(token[:-1]),\n",
    "            'y': torch.tensor(token[1:])\n",
    "        }\n",
    "def collate_fn(batch):\n",
    "    l = torch.tensor([len(item['x']) for item in batch])\n",
    "    sort_ind = torch.argsort(l, descending=True)\n",
    "    x = [item['x'] for item in batch]\n",
    "    y = [item['y'] for item in batch]\n",
    "    \n",
    "    sort_x = [x[i] for i in sort_ind]\n",
    "    sort_y = [y[i] for i in sort_ind]\n",
    "\n",
    "    pad_x = pad_sequence(sort_x, batch_first=True, padding_value=50256)\n",
    "    pad_y = pad_sequence(sort_y, batch_first=True, padding_value=50256)\n",
    "    return {\n",
    "        'lengths': [l[i] for i in sort_ind], \n",
    "        'x': pad_x, \n",
    "        'y': pad_y, \n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "class GRUmodel(nn.Module):\n",
    "    def __init__(self, vocab_size=50257, embed_dim=64, hidden_dim=32, padding_idx=50256):\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding(vocab_size, embed_dim, padding_idx=padding_idx)\n",
    "        self.gru = nn.GRU(embed_dim, hidden_dim, batch_first=True, bidirectional=False)\n",
    "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
    "\n",
    "    def forward(self, x, lengths=None):\n",
    "        emb = self.emb(x)\n",
    "        if lengths is not None:\n",
    "            packed_emb = pack_padded_sequence(emb, lengths, batch_first=True, enforce_sorted=False)\n",
    "            out, _ = self.gru(packed_emb)\n",
    "            out, _ = pad_packed_sequence(out, batch_first=True)\n",
    "        else:\n",
    "            out, _ = self.gru(emb)\n",
    "        logits = self.fc(out)\n",
    "        return logits\n",
    "\n",
    "    def generate(self, context_tokens, max_new_tokens=10, temperature=1.0):\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            generated = context_tokens.clone()\n",
    "\n",
    "            for _ in range(max_new_tokens):\n",
    "                logits = self(generated)  \n",
    "                next_logits = logits[0, -1, :] / temperature \n",
    "                probs = torch.softmax(next_logits, dim=-1)\n",
    "                next_token = torch.multinomial(probs, num_samples=1)\n",
    "                generated = torch.cat([generated, next_token.unsqueeze(0)], dim=1)\n",
    "                if next_token.item() == self.emb.padding_idx:\n",
    "                    break\n",
    "\n",
    "            return generated\n",
    "        \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "import evaluate  \n",
    "\n",
    "\n",
    "rouge = evaluate.load(\"rouge\")\n",
    "\n",
    "def train_loop(dataloader, model, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in dataloader:\n",
    "        x = batch['x'].to(device)\n",
    "        y = batch['y'].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(x)\n",
    "        loss = criterion(logits.view(-1, logits.size(-1)), y.view(-1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "def val_loop(dataloader, model, criterion, tokenizer, device, num_samples=3):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_preds = []\n",
    "    all_refs = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(dataloader):\n",
    "            x = batch['x'].to(device)\n",
    "            y = batch['y'].to(device)\n",
    "\n",
    "            logits = model(x)\n",
    "            loss = criterion(logits.view(-1, logits.size(-1)), y.view(-1))\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # Соберём первые несколько реальных и предсказанных последовательностей\n",
    "            if i == 0:\n",
    "                for j in range(min(num_samples, x.size(0))):\n",
    "                    # Реальный таргет (без паддингов)\n",
    "                    ref_tokens = y[j].cpu().tolist()\n",
    "                    ref_tokens = [t for t in ref_tokens if t != tokenizer.pad_token_id]\n",
    "                    ref_text = tokenizer.decode(ref_tokens, skip_special_tokens=True)\n",
    "\n",
    "                    # Генерация (используем только начало x как контекст)\n",
    "                    context = x[j:j+1]  # (1, T)\n",
    "                    generated = model.generate(context, max_new_tokens=20, temperature=0.7)\n",
    "\n",
    "                    # Декодируем сгенерированное (без контекста)\n",
    "                    gen_tokens = generated[0, context.size(1):].cpu().tolist()\n",
    "                    gen_tokens = [t for t in gen_tokens if t != tokenizer.pad_token_id and t != tokenizer.eos_token_id]\n",
    "                    gen_text = tokenizer.decode(gen_tokens, skip_special_tokens=True)\n",
    "\n",
    "                    all_refs.append(ref_text)\n",
    "                    all_preds.append(gen_text)\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    rouge_scores = rouge.compute(predictions=all_preds, references=all_refs)\n",
    "    return avg_loss, rouge_scores, list(zip(all_refs, all_preds))\n",
    "\n",
    "\n",
    "trainds = AutoTextDataset(train)\n",
    "valds = AutoTextDataset(val)\n",
    "train_loader = DataLoader(trainds, shuffle=True, batch_size=32, collate_fn=collate_fn)\n",
    "val_loader = DataLoader(valds, shuffle=False, batch_size=32, collate_fn=collate_fn)\n",
    "model = GRUmodel()\n",
    "device = 'cuda'\n",
    "optimizer = Adam(model.parameters(), lr=5e-4)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=50256)\n",
    "model.to(device)\n",
    "epochs = 5\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"openai-community/gpt2\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f\"\\nEpoch {epoch + 1}/{epochs}\")\n",
    "    train_loss = train_loop(train_loader, model, optimizer, criterion, device)\n",
    "    print(f\"Train Loss: {train_loss:.4f}\")\n",
    "\n",
    "    val_loss, rouge_scores, samples = val_loop(val_loader, model, criterion, tokenizer, device)\n",
    "    print(f\"Val Loss: {val_loss:.4f}\")\n",
    "    \n",
    "    print(\"ROUGE-1:\", rouge_scores['rouge1'])\n",
    "    print(\"ROUGE-2:\", rouge_scores['rouge2'])\n",
    "    print(\"ROUGE-L:\", rouge_scores['rougeL'])\n",
    "\n",
    "    print(\"\\nПримеры автодополнений:\")\n",
    "    for ref, gen in samples[:3]:\n",
    "        print(f\"Ожидание: {ref}\")\n",
    "        print(f\"Модель:   {gen}\")\n",
    "        print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b741a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainds = AutoTextDataset(train)\n",
    "valds = AutoTextDataset(val)\n",
    "dl_train = DataLoader(trainds, shuffle=True, batch_size=8, collate_fn=collate_fn)\n",
    "dl_val = DataLoader(valds, shuffle=False, batch_size=16, collate_fn=collate_fn)\n",
    "model = GRUmodel()\n",
    "crit = nn.CrossEntropyLoss(ignore_index=50256)\n",
    "opt = torch.optim.Adam(model.parameters())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f111cb1b",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 7\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptim\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Adam\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mevaluate\u001b[39;00m  \n\u001b[1;32m----> 7\u001b[0m rouge \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrouge\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mtrain_loop\u001b[39m(dataloader, model, optimizer, criterion, device):\n\u001b[0;32m     10\u001b[0m     model\u001b[38;5;241m.\u001b[39mtrain()\n",
      "File \u001b[1;32md:\\projects2025\\Yandex\\autotext\\Lib\\site-packages\\evaluate\\loading.py:748\u001b[0m, in \u001b[0;36mload\u001b[1;34m(path, config_name, module_type, process_id, num_process, cache_dir, experiment_id, keep_in_memory, download_config, download_mode, revision, **init_kwargs)\u001b[0m\n\u001b[0;32m    703\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Load a [`~evaluate.EvaluationModule`].\u001b[39;00m\n\u001b[0;32m    704\u001b[0m \n\u001b[0;32m    705\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    745\u001b[0m \u001b[38;5;124;03m    ```\u001b[39;00m\n\u001b[0;32m    746\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    747\u001b[0m download_mode \u001b[38;5;241m=\u001b[39m DownloadMode(download_mode \u001b[38;5;129;01mor\u001b[39;00m DownloadMode\u001b[38;5;241m.\u001b[39mREUSE_DATASET_IF_EXISTS)\n\u001b[1;32m--> 748\u001b[0m evaluation_module \u001b[38;5;241m=\u001b[39m \u001b[43mevaluation_module_factory\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    749\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodule_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodule_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_mode\u001b[49m\n\u001b[0;32m    750\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    751\u001b[0m evaluation_cls \u001b[38;5;241m=\u001b[39m import_main_class(evaluation_module\u001b[38;5;241m.\u001b[39mmodule_path)\n\u001b[0;32m    752\u001b[0m evaluation_instance \u001b[38;5;241m=\u001b[39m evaluation_cls(\n\u001b[0;32m    753\u001b[0m     config_name\u001b[38;5;241m=\u001b[39mconfig_name,\n\u001b[0;32m    754\u001b[0m     process_id\u001b[38;5;241m=\u001b[39mprocess_id,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    760\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minit_kwargs,\n\u001b[0;32m    761\u001b[0m )\n",
      "File \u001b[1;32md:\\projects2025\\Yandex\\autotext\\Lib\\site-packages\\evaluate\\loading.py:639\u001b[0m, in \u001b[0;36mevaluation_module_factory\u001b[1;34m(path, module_type, revision, download_config, download_mode, force_local_path, dynamic_modules_path, **download_kwargs)\u001b[0m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m current_type \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetric\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcomparison\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmeasurement\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m    632\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    633\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mHubEvaluationModuleFactory\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    634\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mevaluate-\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mcurrent_type\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mpath\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    635\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    636\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    637\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdownload_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    638\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdynamic_modules_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdynamic_modules_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m--> 639\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    640\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[0;32m    641\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[1;32md:\\projects2025\\Yandex\\autotext\\Lib\\site-packages\\evaluate\\loading.py:496\u001b[0m, in \u001b[0;36mHubEvaluationModuleFactory.get_module\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    489\u001b[0m local_imports \u001b[38;5;241m=\u001b[39m _download_additional_modules(\n\u001b[0;32m    490\u001b[0m     name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname,\n\u001b[0;32m    491\u001b[0m     base_path\u001b[38;5;241m=\u001b[39mhf_hub_url(path\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m, revision\u001b[38;5;241m=\u001b[39mrevision),\n\u001b[0;32m    492\u001b[0m     imports\u001b[38;5;241m=\u001b[39mimports,\n\u001b[0;32m    493\u001b[0m     download_config\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdownload_config,\n\u001b[0;32m    494\u001b[0m )\n\u001b[0;32m    495\u001b[0m \u001b[38;5;66;03m# copy the script and the files in an importable directory\u001b[39;00m\n\u001b[1;32m--> 496\u001b[0m dynamic_modules_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdynamic_modules_path \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdynamic_modules_path \u001b[38;5;28;01melse\u001b[39;00m \u001b[43minit_dynamic_modules\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    497\u001b[0m module_path, \u001b[38;5;28mhash\u001b[39m \u001b[38;5;241m=\u001b[39m _create_importable_file(\n\u001b[0;32m    498\u001b[0m     local_path\u001b[38;5;241m=\u001b[39mlocal_path,\n\u001b[0;32m    499\u001b[0m     local_imports\u001b[38;5;241m=\u001b[39mlocal_imports,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    504\u001b[0m     download_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdownload_mode,\n\u001b[0;32m    505\u001b[0m )\n\u001b[0;32m    506\u001b[0m \u001b[38;5;66;03m# make the new module to be noticed by the import system\u001b[39;00m\n",
      "File \u001b[1;32md:\\projects2025\\Yandex\\autotext\\Lib\\site-packages\\evaluate\\loading.py:67\u001b[0m, in \u001b[0;36minit_dynamic_modules\u001b[1;34m(name, hf_modules_cache)\u001b[0m\n\u001b[0;32m     65\u001b[0m hf_modules_cache \u001b[38;5;241m=\u001b[39m init_hf_modules(hf_modules_cache)\n\u001b[0;32m     66\u001b[0m dynamic_modules_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(hf_modules_cache, name)\n\u001b[1;32m---> 67\u001b[0m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmakedirs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdynamic_modules_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexist_ok\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(dynamic_modules_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__init__.py\u001b[39m\u001b[38;5;124m\"\u001b[39m)):\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(dynamic_modules_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__init__.py\u001b[39m\u001b[38;5;124m\"\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32m<frozen os>:213\u001b[0m, in \u001b[0;36mmakedirs\u001b[1;34m(name, mode, exist_ok)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "import evaluate  \n",
    "\n",
    "\n",
    "rouge = evaluate.load(\"rouge\")\n",
    "\n",
    "def train_loop(dataloader, model, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in dataloader:\n",
    "        x = batch['x'].to(device)\n",
    "        y = batch['y'].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(x)\n",
    "        loss = criterion(logits.view(-1, logits.size(-1)), y.view(-1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "def val_loop(dataloader, model, criterion, tokenizer, device, num_samples=3):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_preds = []\n",
    "    all_refs = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(dataloader):\n",
    "            x = batch['x'].to(device)\n",
    "            y = batch['y'].to(device)\n",
    "\n",
    "            logits = model(x)\n",
    "            loss = criterion(logits.view(-1, logits.size(-1)), y.view(-1))\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # Соберём первые несколько реальных и предсказанных последовательностей\n",
    "            if i == 0:\n",
    "                for j in range(min(num_samples, x.size(0))):\n",
    "                    # Реальный таргет (без паддингов)\n",
    "                    ref_tokens = y[j].cpu().tolist()\n",
    "                    ref_tokens = [t for t in ref_tokens if t != tokenizer.pad_token_id]\n",
    "                    ref_text = tokenizer.decode(ref_tokens, skip_special_tokens=True)\n",
    "\n",
    "                    # Генерация (используем только начало x как контекст)\n",
    "                    context = x[j:j+1]  # (1, T)\n",
    "                    generated = model.generate(context, max_new_tokens=20, temperature=0.7)\n",
    "\n",
    "                    # Декодируем сгенерированное (без контекста)\n",
    "                    gen_tokens = generated[0, context.size(1):].cpu().tolist()\n",
    "                    gen_tokens = [t for t in gen_tokens if t != tokenizer.pad_token_id and t != tokenizer.eos_token_id]\n",
    "                    gen_text = tokenizer.decode(gen_tokens, skip_special_tokens=True)\n",
    "\n",
    "                    all_refs.append(ref_text)\n",
    "                    all_preds.append(gen_text)\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    rouge_scores = rouge.compute(predictions=all_preds, references=all_refs)\n",
    "    return avg_loss, rouge_scores, list(zip(all_refs, all_preds))\n",
    "\n",
    "\n",
    "trainds = AutoTextDataset(train)\n",
    "valds = AutoTextDataset(val)\n",
    "train_loader = DataLoader(trainds, shuffle=True, batch_size=32, collate_fn=collate_fn)\n",
    "val_loader = DataLoader(valds, shuffle=False, batch_size=32, collate_fn=collate_fn)\n",
    "model = GRUmodel()\n",
    "device = 'cuda'\n",
    "optimizer = Adam(model.parameters(), lr=5e-4)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=50256)\n",
    "model.to(device)\n",
    "epochs = 5\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"openai-community/gpt2\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f\"\\nEpoch {epoch + 1}/{epochs}\")\n",
    "    train_loss = train_loop(train_loader, model, optimizer, criterion, device)\n",
    "    print(f\"Train Loss: {train_loss:.4f}\")\n",
    "    val_loss, rouge_scores, samples = val_loop(val_loader, model, criterion, tokenizer, device)\n",
    "    print(f\"Val Loss: {val_loss:.4f}\")\n",
    "    print(\"ROUGE-1:\", rouge_scores['rouge1'])\n",
    "    print(\"ROUGE-2:\", rouge_scores['rouge2'])\n",
    "    print(\"ROUGE-L:\", rouge_scores['rougeL'])\n",
    "\n",
    "    print(\"\\nПримеры автодополнений:\")\n",
    "    for ref, gen in samples[:3]:\n",
    "        print(f\"Ожидание: {ref}\")\n",
    "        print(f\"Модель:   {gen}\")\n",
    "        print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "82b8d5f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.2349, -0.2167,  0.0902,  ...,  0.0549, -0.1867, -0.0376],\n",
      "         [-0.3318, -0.4711,  0.0452,  ...,  0.2100, -0.5133, -0.2629],\n",
      "         [-0.3801, -0.2510, -0.0786,  ...,  0.2460, -0.5038, -0.3385],\n",
      "         ...,\n",
      "         [ 0.2215,  0.0978,  0.1000,  ..., -0.3724, -0.1006, -0.0493],\n",
      "         [-0.2423, -0.1464, -0.0303,  ..., -0.3090, -0.2128,  0.0755],\n",
      "         [-0.2284, -0.0895, -0.1916,  ..., -0.1869, -0.2602,  0.0476]],\n",
      "\n",
      "        [[ 0.0170, -0.0060,  0.0589,  ...,  0.0716, -0.3858, -0.1723],\n",
      "         [-0.4506, -0.4831,  0.0475,  ...,  0.4309, -0.5493,  0.1163],\n",
      "         [ 0.0202, -0.1068,  0.0999,  ...,  0.4084, -0.3107,  0.1242],\n",
      "         ...,\n",
      "         [-0.0456, -0.1237, -0.0253,  ...,  0.1337, -0.2808, -0.1375],\n",
      "         [-0.0456, -0.1237, -0.0253,  ...,  0.1337, -0.2808, -0.1375],\n",
      "         [-0.0456, -0.1237, -0.0253,  ...,  0.1337, -0.2808, -0.1375]]],\n",
      "       grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for batch in dl_train:\n",
    "    pred = model(batch['x'])\n",
    "    print(pred)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "700630eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 31, 50257])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "1c82a47c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2349, -0.2167,  0.0902,  ...,  0.0549, -0.1867, -0.0376],\n",
       "        [-0.3318, -0.4711,  0.0452,  ...,  0.2100, -0.5133, -0.2629],\n",
       "        [-0.3801, -0.2510, -0.0786,  ...,  0.2460, -0.5038, -0.3385],\n",
       "        ...,\n",
       "        [-0.0456, -0.1237, -0.0253,  ...,  0.1337, -0.2808, -0.1375],\n",
       "        [-0.0456, -0.1237, -0.0253,  ...,  0.1337, -0.2808, -0.1375],\n",
       "        [-0.0456, -0.1237, -0.0253,  ...,  0.1337, -0.2808, -0.1375]],\n",
       "       grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.view(-1, pred.size(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "99dbc7dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3073, 14343,   262,  9082,  2513,   263,   300,    76,    69,  5488,\n",
       "            11,  2632,   807,   477,   262,   835,    11,   703,  1282,   345,\n",
       "          9099,   470,  3031,   736,  2063,   262,   640, 50256],\n",
       "        [ 6621, 42254,   290,   318,  1016,    70, 50256, 50256, 50256, 50256,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256]])"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "50d9f8da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 3073, 14343,   262,  9082,  2513,   263,   300,    76,    69,  5488,\n",
       "           11,  2632,   807,   477,   262,   835,    11,   703,  1282,   345,\n",
       "         9099,   470,  3031,   736,  2063,   262,   640, 50256,  6621, 42254,\n",
       "          290,   318,  1016,    70, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "        50256, 50256, 50256, 50256, 50256, 50256])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['y'].view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "a072efaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "crit = nn.CrossEntropyLoss(ignore_index=50256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "862b2502",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(10.8438, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crit(pred.view(-1, pred.size(-1)), batch['y'].view(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "b5cd0a47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50257"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "aaedce29",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"openai-community/gpt2\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fbcbe5d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[25374, 11, 582]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(\"HI, man\", add_special_tokens=True).input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "224a4fbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50256"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f527897b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441a94f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autotext (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
